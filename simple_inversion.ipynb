{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inversion of 2 by 2 matrices using an operator recurrent neural network\n",
    "\n",
    "We use a simplified version of the network architecture proposed in the preprint\n",
    "\n",
    "> Maarten V. de Hoop, Matti Lassas, Christopher A. Wong. _Deep learning architectures for nonlinear operator functions and nonlinear inverse problems_. [arXiv:1912.11090](https://arxiv.org/abs/1912.11090)\n",
    "\n",
    "and teach it to invert matrices $X$ of the form $X = R D R^T$ where\n",
    "\n",
    "$$\n",
    "R = \\begin{pmatrix}\n",
    "c & -s\n",
    "\\\\\n",
    "s & c\n",
    "\\end{pmatrix},\n",
    "\\quad\n",
    "D = \\begin{pmatrix}\n",
    "\\lambda_1 & 0\n",
    "\\\\\n",
    "0 & \\lambda_2\n",
    "\\end{pmatrix},\n",
    "$$\n",
    "$c = \\cos(\\alpha)$ and $s = \\sin(\\alpha)$ for some $\\alpha \\in (0,2\\pi)$,\n",
    "and $\\lambda_j \\in (1/2, 3/2)$, $j=1,2$.\n",
    "\n",
    "We use notations as in version 3 of the preprint (revised 3 Jan 2022). The notation is different in earlier version.\n",
    "\n",
    "In the code, variables have the same meaning as in the [Quickstart](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html) guige of PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "The operator recurrent architecture is implemented in `opnet` module, and \n",
    "generation of learning data in `simple_inversion_data`. \n",
    "\n",
    "File `PATH` is used to save the parameters of the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import opnet\n",
    "from simple_inversion_data import generate_data, save_data, load_data\n",
    "\n",
    "PATH = './simple_inversion_net.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the network model and the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dim = 2 # use 2 x 2 matrices\n",
    "num_layers = 10\n",
    "model = opnet.OperatorNet(dim, num_layers, useReLU=True)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of training data\n",
    "\n",
    "Training data consists of pairs $(X,y)$ where $X$ is an invertible $2 \\times 2$ matrix and $y = X^{-1} v$\n",
    "where $v = (1,1) \\in \\mathbb{R}^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(*generate_data(60000), \"simple_inversion_train_data.npz\")\n",
    "save_data(*generate_data(10000), \"simple_inversion_test_data.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    load_data(\"simple_inversion_train_data.npz\"), \n",
    "    batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the optimization method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate parameter is from the quickstart guide \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over the training data multiple times (epochs) and \n",
    "save the optimized parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.494667  [   64/60000]\n",
      "loss: 0.829158  [ 6464/60000]\n",
      "loss: 0.503941  [12864/60000]\n",
      "loss: 0.387115  [19264/60000]\n",
      "loss: 0.286722  [25664/60000]\n",
      "loss: 0.220588  [32064/60000]\n",
      "loss: 0.098816  [38464/60000]\n",
      "loss: 0.145932  [44864/60000]\n",
      "loss: 0.099505  [51264/60000]\n",
      "loss: 0.094849  [57664/60000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.051868  [   64/60000]\n",
      "loss: 0.070272  [ 6464/60000]\n",
      "loss: 0.080148  [12864/60000]\n",
      "loss: 0.079284  [19264/60000]\n",
      "loss: 0.073467  [25664/60000]\n",
      "loss: 0.080846  [32064/60000]\n",
      "loss: 0.045498  [38464/60000]\n",
      "loss: 0.066389  [44864/60000]\n",
      "loss: 0.045753  [51264/60000]\n",
      "loss: 0.047228  [57664/60000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.026220  [   64/60000]\n",
      "loss: 0.042018  [ 6464/60000]\n",
      "loss: 0.048453  [12864/60000]\n",
      "loss: 0.052453  [19264/60000]\n",
      "loss: 0.046033  [25664/60000]\n",
      "loss: 0.053160  [32064/60000]\n",
      "loss: 0.030815  [38464/60000]\n",
      "loss: 0.047430  [44864/60000]\n",
      "loss: 0.030855  [51264/60000]\n",
      "loss: 0.035569  [57664/60000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.018824  [   64/60000]\n",
      "loss: 0.031910  [ 6464/60000]\n",
      "loss: 0.036266  [12864/60000]\n",
      "loss: 0.044637  [19264/60000]\n",
      "loss: 0.036470  [25664/60000]\n",
      "loss: 0.042528  [32064/60000]\n",
      "loss: 0.025577  [38464/60000]\n",
      "loss: 0.040090  [44864/60000]\n",
      "loss: 0.026491  [51264/60000]\n",
      "loss: 0.030646  [57664/60000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.015970  [   64/60000]\n",
      "loss: 0.027153  [ 6464/60000]\n",
      "loss: 0.030110  [12864/60000]\n",
      "loss: 0.039358  [19264/60000]\n",
      "loss: 0.031317  [25664/60000]\n",
      "loss: 0.036801  [32064/60000]\n",
      "loss: 0.022285  [38464/60000]\n",
      "loss: 0.035166  [44864/60000]\n",
      "loss: 0.023392  [51264/60000]\n",
      "loss: 0.026366  [57664/60000]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5): \n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    for batch, (X, y) in enumerate(train_loader):\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print statistics\n",
    "        if batch % 100 == 0:\n",
    "            n, N = (batch + 1) * len(X), len(train_loader.dataset)\n",
    "            print(f\"loss: {loss.item():>7f}  [{n:>5d}/{N:>5d}]\")\n",
    "\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "If we have already trained the network, we can just load its parameters. (Note that we still need to run the initialization.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load trained variables\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the testing data\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    load_data(\"simple_inversion_test_data.npz\"), \n",
    "    batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute a couple of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: \n",
      "tensor([[[1.5568],\n",
      "         [1.3852]],\n",
      "\n",
      "        [[1.4132],\n",
      "         [0.6738]]])\n",
      "Prediction: \n",
      "tensor([[[1.4227],\n",
      "         [1.4599]],\n",
      "\n",
      "        [[1.0734],\n",
      "         [0.7257]]])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(test_loader)\n",
    "X, y = dataiter.next()\n",
    "with torch.no_grad():\n",
    "    pred = model(X)\n",
    "print(\"True: \")\n",
    "print(y[:2])\n",
    "print(\"Prediction: \")\n",
    "print(pred[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 0.022507 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_batches = len(test_loader)\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for X, y in test_loader:\n",
    "        pred = model(X)\n",
    "        test_loss += loss_fn(pred, y).item()\n",
    "test_loss /= num_batches\n",
    "print(f\"Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('oprecnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ce332c1bcad4f5e41296b22dcf9e1de410a09ca344ec44ac587ddf92bae6cd1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
